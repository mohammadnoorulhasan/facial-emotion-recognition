{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author                 :  Mohammad Noor Ul Hasan\n",
    "# Start Date             :  13/Feb/19\n",
    "\n",
    "# Dependencies(Modules ) :  keras \n",
    "# \t\t\t\t\t\t\tpandas\n",
    "# \t\t\t\t\t\t\tcv2\n",
    "# \t\t\t\t\t\t\tnumpy\n",
    "# Last Edited            :  10/Apr/19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/fer2013.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_path = 'dataset/fer2013.csv'\n",
    "image_shape = (48,48)\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load dataset, extract images and emotions '''\n",
    "\n",
    "def load_dataset():\n",
    "    # load csv\n",
    "    data = pd.read_csv(dataset_path)\n",
    "#     print('\\nDataset glimpse : \\n',data.head())\n",
    "    \n",
    "    # save all the pixels values to list 'pixels' \n",
    "    pixels_of_images = data['pixels'].tolist()\n",
    "#     print('\\nTotal number of images : ',len(pixels_of_images))\n",
    "\n",
    "#     print('\\nData type of pixel values : ',type(pixels_of_images[0]),'\\nLength of pixels per image : ' ,len(pixels_of_images[0]))\n",
    "    ## which is not equals to 2304\n",
    "    \n",
    "    # to store faces\n",
    "    images = []\n",
    "    # get all images with pixels values 48*48=2304\n",
    "    for image_pixels in pixels_of_images:\n",
    "        # face contains pixels value of single image\n",
    "        image = [int(pixel) for pixel in image_pixels.split(' ')]\n",
    "#         print('\\n\\n Image length (Single image pixels with 48*48 dimensions):', len(image))\n",
    "        # convert image into array\n",
    "        image = np.asarray(image).reshape(image_shape[0], image_shape[1])\n",
    "        # save the image into images array\n",
    "        images.append(image.astype('float32'))\n",
    "        \n",
    "\n",
    "    # convert images list into array\n",
    "    images = np.asarray(images)\n",
    "    print('\\nShape before expanding dimensions : ',images.shape)\n",
    "    \n",
    "    # expand images dimensions\n",
    "    images = np.expand_dims(images, -1)\n",
    "    print('\\nShape after expanding dimensions : ',images.shape)\n",
    "    \n",
    "    # extract emotions and do one-hot encoding\n",
    "    emotions = pd.get_dummies(data['emotion'])\n",
    "    \n",
    "    return images, emotions\n",
    "\n",
    "\n",
    "''' Preprocess all the images '''\n",
    "\n",
    "def preprocess_images(images, temp=True):\n",
    "    images = images.astype('float32')\n",
    "    images = images/255.0\n",
    "    \n",
    "#     print(images[0][0])\n",
    "    if temp :\n",
    "        images = images - 0.5\n",
    "        images = images * 2.0\n",
    "        \n",
    "#         print(images[0][0])\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape before expanding dimensions :  (35887, 48, 48)\n",
      "\n",
      "Shape after expanding dimensions :  (35887, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "''' Driver Code '''\n",
    "\n",
    "# load dataset \n",
    "images, emotions = load_dataset()\n",
    "\n",
    "# preprocess the images\n",
    "images = preprocess_images(images, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 46, 46, 8)    72          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 46, 46, 8)    32          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 46, 46, 8)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 44, 44, 8)    576         activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 44, 44, 8)    32          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 44, 44, 8)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_49 (SeparableC (None, 44, 44, 16)   200         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 44, 44, 16)   0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_50 (SeparableC (None, 44, 44, 16)   400         activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 22, 22, 16)   128         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 22, 22, 16)   0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 22, 22, 16)   64          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 22, 22, 16)   0           max_pooling2d_25[0][0]           \n",
      "                                                                 batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_51 (SeparableC (None, 22, 22, 32)   656         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 22, 22, 32)   0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_52 (SeparableC (None, 22, 22, 32)   1312        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 11, 11, 32)   512         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 11, 11, 32)   0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 11, 11, 32)   128         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 11, 11, 32)   0           max_pooling2d_26[0][0]           \n",
      "                                                                 batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_53 (SeparableC (None, 11, 11, 64)   2336        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 11, 11, 64)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_54 (SeparableC (None, 11, 11, 64)   4672        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 6, 6, 64)     2048        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 6, 6, 64)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 6, 6, 64)     256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 6, 6, 64)     0           max_pooling2d_27[0][0]           \n",
      "                                                                 batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_55 (SeparableC (None, 6, 6, 128)    8768        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 6, 6, 128)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_56 (SeparableC (None, 6, 6, 128)    17536       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 3, 3, 128)    8192        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 3, 3, 128)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 3, 3, 128)    512         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 3, 3, 128)    0           max_pooling2d_28[0][0]           \n",
      "                                                                 batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 3, 3, 7)      8071        add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 7)            0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_7[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "898/897 [==============================] - 204s 228ms/step - loss: 1.7437 - acc: 0.3354 - val_loss: 1.5631 - val_acc: 0.4172\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.56314, saving model to models/_mini_XCEPTION.01-0.42.hdf5\n",
      "Epoch 2/110\n",
      "898/897 [==============================] - 206s 230ms/step - loss: 1.4929 - acc: 0.4410 - val_loss: 1.4780 - val_acc: 0.4558\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.56314 to 1.47803, saving model to models/_mini_XCEPTION.02-0.46.hdf5\n",
      "Epoch 3/110\n",
      "898/897 [==============================] - 206s 229ms/step - loss: 1.3807 - acc: 0.4821 - val_loss: 1.4424 - val_acc: 0.4965\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.47803 to 1.44239, saving model to models/_mini_XCEPTION.03-0.50.hdf5\n",
      "Epoch 4/110\n",
      "898/897 [==============================] - 202s 225ms/step - loss: 1.3164 - acc: 0.5064 - val_loss: 1.2885 - val_acc: 0.5258\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.44239 to 1.28847, saving model to models/_mini_XCEPTION.04-0.53.hdf5\n",
      "Epoch 5/110\n",
      "898/897 [==============================] - 205s 228ms/step - loss: 1.2761 - acc: 0.5234 - val_loss: 1.2889 - val_acc: 0.5169\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.28847\n",
      "Epoch 6/110\n",
      "898/897 [==============================] - 199s 221ms/step - loss: 1.2388 - acc: 0.5335 - val_loss: 1.1916 - val_acc: 0.5506\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.28847 to 1.19158, saving model to models/_mini_XCEPTION.06-0.55.hdf5\n",
      "Epoch 7/110\n",
      "898/897 [==============================] - 204s 228ms/step - loss: 1.2151 - acc: 0.5421 - val_loss: 1.1853 - val_acc: 0.5557\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.19158 to 1.18529, saving model to models/_mini_XCEPTION.07-0.56.hdf5\n",
      "Epoch 8/110\n",
      "898/897 [==============================] - 204s 227ms/step - loss: 1.1934 - acc: 0.5559 - val_loss: 1.2589 - val_acc: 0.5295\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.18529\n",
      "Epoch 9/110\n",
      "898/897 [==============================] - 203s 226ms/step - loss: 1.1686 - acc: 0.5607 - val_loss: 1.2050 - val_acc: 0.5483\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.18529\n",
      "Epoch 10/110\n",
      "646/897 [====================>.........] - ETA: 1:03 - loss: 1.1529 - acc: 0.5719"
     ]
    }
   ],
   "source": [
    "xtrain, xtest,ytrain,ytest = train_test_split(images, emotions,test_size=0.2,shuffle=True)\n",
    "\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D, AveragePooling2D, BatchNormalization, GlobalAveragePooling2D, Flatten, Input, MaxPooling2D, SeparableConv2D\n",
    "from keras.regularizers import l2\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 110\n",
    "input_shape = (48, 48, 1)\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = 'models/'\n",
    "l2_regularization=0.01\n",
    " \n",
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    " \n",
    "# model parameters\n",
    "regularization = l2(l2_regularization)\n",
    " \n",
    "# base\n",
    "img_input = Input(input_shape)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    " \n",
    "# module 1\n",
    "residual = Conv2D(16, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 2\n",
    "residual = Conv2D(32, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 3\n",
    "residual = Conv2D(64, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 4\n",
    "residual = Conv2D(128, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "x = Conv2D(num_classes, (3, 3), padding='same')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Activation('softmax',name='predictions')(x)\n",
    " \n",
    "model = Model(img_input, output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    " \n",
    "# callbacks\n",
    "log_file_path = base_path + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    " \n",
    "model.fit_generator(data_generator.flow(xtrain, ytrain,batch_size),\n",
    "                        steps_per_epoch=len(xtrain) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=(xtest,ytest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
